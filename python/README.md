# Track India - Backend API Server

> AI-powered Flask backend for Indian infrastructure development tracking with RAG (Retrieval-Augmented Generation) and automated data fetching

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-3.0.0-green.svg)](https://flask.palletsprojects.com/)
[![ChromaDB](https://img.shields.io/badge/ChromaDB-Vector%20DB-orange.svg)](https://www.trychroma.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## üìã Table of Contents

- [Overview](#overview)
- [System Architecture](#system-architecture)
- [Features](#features)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Configuration](#configuration)
- [API Documentation](#api-documentation)
- [Data Pipeline](#data-pipeline)
- [RAG System](#rag-system)
- [Development](#development)

---

## üéØ Overview

Track India Backend is a sophisticated Flask-based API server that provides real-time infrastructure development data, AI-powered chat capabilities, and predictive analytics for Indian government projects. The system automatically fetches data from multiple sources, processes it through a vector database, and serves it via RESTful endpoints.

### Key Capabilities

- ü§ñ **RAG-powered AI Chat** using Google Gemini Pro
- üìä **Real-time Data Fetching** from NewsAPI and data.gov.in
- üîÑ **Automated Scheduling** with intelligent caching (6-hour intervals)
- üóÑÔ∏è **Vector Database** with ChromaDB Cloud for semantic search
- üìà **Dynamic Statistics** and filtering
- üîç **Semantic Search** across 50-150 infrastructure updates

---

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     Track India Backend                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Data Sources    ‚îÇ         ‚îÇ  Processing      ‚îÇ         ‚îÇ  Storage         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ NewsAPI        ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Data Fetcher     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ JSON Cache       ‚îÇ
‚îÇ ‚Ä¢ data.gov.in    ‚îÇ         ‚îÇ ‚Ä¢ Scheduler      ‚îÇ         ‚îÇ ‚Ä¢ fetched_data   ‚îÇ
‚îÇ ‚Ä¢ Catalog Search ‚îÇ         ‚îÇ ‚Ä¢ Parser         ‚îÇ         ‚îÇ ‚Ä¢ timestamps     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ ‚Ä¢ Transformer    ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
                                      ‚îÇ                            ‚îÇ
                                      ‚ñº                            ‚ñº
                             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                             ‚îÇ Vector Database  ‚îÇ         ‚îÇ  API Endpoints   ‚îÇ
                             ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                             ‚îÇ ‚Ä¢ ChromaDB Cloud ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Flask REST API   ‚îÇ
                             ‚îÇ ‚Ä¢ 384-dim        ‚îÇ         ‚îÇ ‚Ä¢ /api/updates   ‚îÇ
                             ‚îÇ ‚Ä¢ Embeddings     ‚îÇ         ‚îÇ ‚Ä¢ /api/stats     ‚îÇ
                             ‚îÇ ‚Ä¢ Semantic Search‚îÇ         ‚îÇ ‚Ä¢ /api/chat      ‚îÇ
                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                      ‚îÇ                            ‚îÇ
                                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                   ‚îÇ
                                                   ‚ñº
                                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                      ‚îÇ   RAG + Gemini AI    ‚îÇ
                                      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                                      ‚îÇ ‚Ä¢ Context Retrieval  ‚îÇ
                                      ‚îÇ ‚Ä¢ AI Generation      ‚îÇ
                                      ‚îÇ ‚Ä¢ Source Citations   ‚îÇ
                                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow Diagram

```
[External APIs] ‚Üí [APScheduler] ‚Üí [Data Fetcher] ‚Üí [JSON Storage]
                                         ‚Üì
                                  [Vector DB Builder]
                                         ‚Üì
                                  [ChromaDB Cloud]
                                         ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚ñº                                          ‚ñº
            [REST Endpoints]                           [RAG Query System]
                    ‚Üì                                          ‚Üì
            [Frontend Client]                          [Gemini Pro AI]
```

---

## ‚ú® Features

### üîÑ Automated Data Fetching

- **Smart Scheduling**: Runs every 6 hours with intelligent cache checking
- **Multiple Sources**:
  - NewsAPI.org (50 articles per fetch)
  - data.gov.in Catalog Search API
- **Cache Management**: Only fetches when data is >6 hours old
- **Auto-Update Vector DB**: Automatically rebuilds embeddings after fetch

### ü§ñ RAG-Powered AI Chat

- **Semantic Search**: Retrieves relevant context from vector database
- **AI Generation**: Google Gemini Pro for natural language responses
- **Source Citations**: Returns 5 most relevant sources with each answer
- **Context-Aware**: Uses 384-dimensional embeddings for accurate retrieval

### üìä Dynamic API Endpoints

1. **GET /api/updates** - List all updates with filtering
   - Parameters: `type` (all/news/project), `limit` (default: 20)
   - Returns: Paginated list with total count
2. **GET /api/updates/<id>** - Single update with related items
   - Returns: Full details + 5 related updates
3. **GET /api/stats** - Real-time statistics
   - Active projects, total funding, new policies, completed projects
4. **POST /api/chat** - AI-powered chat interface
   - Input: User question
   - Output: AI answer + source citations

### üóÑÔ∏è Vector Database

- **ChromaDB Cloud**: Distributed vector storage
- **Sentence Transformers**: all-MiniLM-L6-v2 model
- **384 Dimensions**: Compact yet accurate embeddings
- **50-150 Records**: Automatically maintained
- **Semantic Search**: k=5 nearest neighbors

---

## üõ†Ô∏è Tech Stack

| Component           | Technology            | Version | Purpose                   |
| ------------------- | --------------------- | ------- | ------------------------- |
| **Web Framework**   | Flask                 | 3.0.0   | REST API server           |
| **CORS**            | Flask-CORS            | 4.0.0   | Cross-origin requests     |
| **Scheduler**       | APScheduler           | 3.11.0  | Automated data fetching   |
| **Vector DB**       | ChromaDB              | 0.5.0+  | Semantic search & storage |
| **Embeddings**      | Sentence Transformers | 2.3.0+  | Text-to-vector conversion |
| **AI Model**        | Google Generative AI  | 0.8.5   | Gemini Pro chat           |
| **ML Framework**    | PyTorch               | 2.2.0+  | Neural network backend    |
| **Data Processing** | Pandas                | 2.1.3   | Data manipulation         |
| **HTTP Client**     | Requests              | 2.31.0  | API calls                 |
| **Environment**     | Python-dotenv         | 1.0.0   | Configuration management  |

---

## üìÅ Project Structure

```
python/
‚îú‚îÄ‚îÄ app.py                      # Main Flask application
‚îú‚îÄ‚îÄ data_fetcher.py             # Automated data fetching system
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ .env                        # Environment variables (not in git)
‚îú‚îÄ‚îÄ example.config.env          # Example configuration
‚îú‚îÄ‚îÄ README.md                   # This file
‚îÇ
‚îú‚îÄ‚îÄ data/                       # Cached data storage
‚îÇ   ‚îî‚îÄ‚îÄ fetched_data.json      # Latest fetched articles (50-150 records)
‚îÇ
‚îú‚îÄ‚îÄ rag/                        # RAG system modules
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ build_vector_db.py     # Vector database builder
‚îÇ   ‚îî‚îÄ‚îÄ query_rag.py           # RAG query system with Gemini
‚îÇ
‚îî‚îÄ‚îÄ venv/                       # Virtual environment (not in git)
```

### Key Files

- **`app.py`**: Main Flask server with all REST endpoints and initialization logic
- **`data_fetcher.py`**: Handles automatic data fetching from NewsAPI and data.gov.in
- **`rag/build_vector_db.py`**: Builds and maintains ChromaDB vector database
- **`rag/query_rag.py`**: RAG system for semantic search + AI generation
- **`data/fetched_data.json`**: JSON cache with timestamp for intelligent refreshing

---

## üöÄ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- Virtual environment (recommended)

### Step 1: Clone Repository

```bash
cd Track-India-Null-Coders/python
```

### Step 2: Create Virtual Environment

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Configure Environment

```bash
# Copy example config
cp example.config.env .env

# Edit .env with your API keys
notepad .env  # Windows
nano .env     # Linux/Mac
```

---

## ‚öôÔ∏è Configuration

Create a `.env` file in the `python/` directory:

```env
# NewsAPI.org - Free tier (100 requests/day)
# Sign up at: https://newsapi.org/register
NEWS_API_KEY=your_newsapi_key_here

# data.gov.in API Key
# Get from: https://data.gov.in/
API_KEY=your_datagovin_key_here

# Google Gemini API Key
# Get from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_key_here

# ChromaDB Cloud API Key
# Get from: https://trychroma.com/
CHROMA_API=your_chroma_key_here
```

### API Key Setup

1. **NewsAPI** (Free):

   - Visit: https://newsapi.org/register
   - Free tier: 100 requests/day
   - Used for: Indian infrastructure news

2. **data.gov.in** (Free):

   - Visit: https://data.gov.in/
   - Register and request API access
   - Used for: Government catalog search

3. **Google Gemini** (Free):

   - Visit: https://makersuite.google.com/app/apikey
   - Free tier available
   - Used for: AI chat responses

4. **ChromaDB Cloud** (Free tier available):
   - Visit: https://trychroma.com/
   - Used for: Vector database storage

---

## üì° API Documentation

### Base URL

```
http://localhost:8010/api
```

### Endpoints

#### 1. Health Check

```http
GET /
```

**Response:**

```json
{
  "status": "running",
  "message": "Track India API Server",
  "version": "1.0",
  "endpoints": ["/api/updates", "/api/stats", "/api/chat"],
  "data_source": "Real API (data.gov.in + NewsAPI)",
  "scheduler": "Active (6-hour intervals)"
}
```

---

#### 2. Get Updates List

```http
GET /api/updates?type=all&limit=20
```

**Query Parameters:**
| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `type` | string | `all` | Filter type: `all`, `news`, `project` |
| `limit` | integer | `20` | Number of results to return |

**Response:**

```json
{
  "success": true,
  "data": [
    {
      "id": "news_0_1761406063",
      "title": "New Metro Line Approved for Mumbai",
      "description": "Government approves 33km metro extension...",
      "category": "news",
      "source": "NewsAPI",
      "published": "2025-01-20T10:30:00Z",
      "url": "https://example.com/article",
      "impact_score": 85
    }
  ],
  "total": 50,
  "filtered": 20,
  "type": "all",
  "limit": 20
}
```

---

#### 3. Get Single Update

```http
GET /api/updates/<id>
```

**Parameters:**
| Parameter | Type | Description |
|-----------|------|-------------|
| `id` | string | Unique update ID (e.g., `news_0_1761406063`) |

**Response:**

```json
{
  "success": true,
  "data": {
    "id": "news_0_1761406063",
    "title": "New Metro Line Approved for Mumbai",
    "description": "Full description...",
    "category": "news",
    "source": "NewsAPI",
    "published": "2025-01-20T10:30:00Z",
    "url": "https://example.com/article",
    "impact_score": 85,
    "metadata": {
      "author": "PTI",
      "tags": ["transport", "mumbai", "metro"]
    }
  },
  "related": [
    {
      "id": "news_1_1761406063",
      "title": "Delhi Metro Phase 4 Update",
      "similarity": 0.87
    }
  ]
}
```

---

#### 4. Get Statistics

```http
GET /api/stats
```

**Response:**

```json
{
  "success": true,
  "data": {
    "active_projects": 247,
    "total_funding": "‚Çπ45,000 Cr",
    "new_policies": 12,
    "completed": 89
  },
  "calculated_from": "real_data",
  "last_updated": "2025-01-20T15:45:00Z"
}
```

---

#### 5. AI Chat (RAG)

```http
POST /api/chat
Content-Type: application/json
```

**Request Body:**

```json
{
  "message": "What are the latest infrastructure projects in Maharashtra?"
}
```

**Response:**

```json
{
  "success": true,
  "answer": "Based on recent data, Maharashtra has several major infrastructure projects...",
  "sources": [
    {
      "id": "news_0_1761406063",
      "title": "Mumbai Metro Extension Approved",
      "url": "https://example.com/article",
      "relevance": 0.92
    }
  ],
  "model": "Gemini Pro",
  "retrieved_contexts": 5
}
```

---

## üîÑ Data Pipeline

### Automated Fetching Process

```python
# APScheduler Configuration
Interval: Every 6 hours
Trigger: Cron-style with cache checking
Cache Duration: 6 hours minimum
```

### Fetch Workflow

1. **Check Cache Age**

   ```python
   if cache_age < 6 hours:
       skip_fetch()
   ```

2. **Fetch from NewsAPI**

   - Query: Indian infrastructure, government, policy news
   - Limit: 50 articles
   - Sort: Latest first

3. **Fetch from data.gov.in**

   - Catalog search API
   - Topics: Infrastructure, education, health, water

4. **Process & Store**

   - Clean and normalize data
   - Add unique IDs and timestamps
   - Save to `data/fetched_data.json`

5. **Update Vector DB**
   - Generate 384-dim embeddings
   - Upsert to ChromaDB Cloud
   - Update metadata

### Data Structure

```json
{
  "last_updated": "2025-01-20T15:45:00Z",
  "total_records": 50,
  "updates": [
    {
      "id": "news_0_1761406063",
      "title": "Article Title",
      "description": "Full description...",
      "category": "news",
      "source": "NewsAPI",
      "published": "2025-01-20T10:30:00Z",
      "url": "https://...",
      "impact_score": 85
    }
  ]
}
```

---

## üß† RAG System

### Architecture

```
User Query ‚Üí Embedding Model ‚Üí Vector Search ‚Üí Context Retrieval
                                                        ‚Üì
User Question + Retrieved Context ‚Üí Gemini Pro ‚Üí AI Answer + Sources
```

### Components

#### 1. Vector Database Builder (`build_vector_db.py`)

- **Model**: sentence-transformers/all-MiniLM-L6-v2
- **Dimensions**: 384
- **Storage**: ChromaDB Cloud
- **Collection**: `indian_infrastructure_data`

#### 2. RAG Query System (`query_rag.py`)

- **Retrieval**: k=5 nearest neighbors
- **Context**: Top 5 most relevant documents
- **Generation**: Google Gemini Pro
- **Output**: Answer + source citations

### Usage Example

```python
from rag.query_rag import initialize_rag, get_rag_query

# Initialize RAG system
initialize_rag()

# Query
rag_query = get_rag_query()
result = rag_query.query("What are the water projects in Karnataka?")

# Result
print(result['answer'])      # AI-generated answer
print(result['sources'])     # List of source documents
```

---

## üíª Development

### Running the Server

```bash
# Activate virtual environment
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# Run Flask app
python app.py
```

**Output:**

```
============================================================
üöÄ INITIALIZING TRACK INDIA SYSTEM
============================================================

1Ô∏è‚É£ Starting data fetcher (6-hour schedule)...
   ‚úÖ Scheduler started
   ‚è∞ Next run: 2025-01-20 21:45:00

2Ô∏è‚É£ Building vector database...
   üì• Loading embedding model...
   ‚úÖ Model loaded: all-MiniLM-L6-v2 (384 dimensions)
   üìÇ Found existing data file
   ‚úÖ Vector database ready: 150 records

3Ô∏è‚É£ Initializing RAG query system...
   ‚úÖ RAG system initialized

============================================================
‚úÖ SYSTEM READY
============================================================
   Server: http://localhost:8010
   Data Sources: data.gov.in + NewsAPI
   AI: Gemini Pro with RAG
   Vector DB: 150 records
   Scheduler: Active
============================================================

 * Running on http://127.0.0.1:8010
```

### Testing Endpoints

```bash
# Health check
curl http://localhost:8010/

# Get updates
curl http://localhost:8010/api/updates?type=all&limit=5

# Get single update
curl http://localhost:8010/api/updates/news_0_1761406063

# Get stats
curl http://localhost:8010/api/stats

# Test chat (PowerShell)
$body = @{ message = "Latest projects?" } | ConvertTo-Json
Invoke-RestMethod -Uri http://localhost:8010/api/chat -Method Post -Body $body -ContentType "application/json"
```

### Manual Data Fetch

```bash
# Force immediate data fetch
python -c "from data_fetcher import fetcher; fetcher.fetch_all_data()"
```

### Rebuild Vector Database

```bash
# Rebuild from cached data
python -c "from rag.build_vector_db import get_builder; get_builder().build_from_file('data/fetched_data.json')"
```

---

## üìä Performance Metrics

| Metric               | Value          |
| -------------------- | -------------- |
| Startup Time         | ~15-20 seconds |
| API Response Time    | <100ms (avg)   |
| Vector Search Time   | <50ms          |
| AI Generation Time   | 2-5 seconds    |
| Data Fetch Interval  | 6 hours        |
| Records Stored       | 50-150         |
| Embedding Dimensions | 384            |

---

## üîß Troubleshooting

### Common Issues

1. **Port Already in Use**

   ```bash
   # Change port in app.py
   app.run(host='0.0.0.0', port=8011, debug=False)
   ```

2. **API Key Errors**

   - Check `.env` file exists
   - Verify API keys are valid
   - Check API rate limits

3. **Vector DB Connection Issues**

   - Verify ChromaDB API key
   - Check internet connection
   - Ensure tenant ID is correct

4. **Import Errors**
   - Reinstall dependencies: `pip install -r requirements.txt --upgrade`
   - Check Python version: `python --version` (3.8+)

---

## üîê Security Notes

- Never commit `.env` file to git
- Rotate API keys regularly
- Use environment variables for all secrets
- Enable CORS only for trusted domains in production
- Implement rate limiting for production use

---

## üìà Future Enhancements

- [ ] Database integration (PostgreSQL/MongoDB)
- [ ] Caching layer (Redis)
- [ ] Authentication & authorization
- [ ] Rate limiting per API key
- [ ] WebSocket support for real-time updates
- [ ] Advanced analytics dashboard
- [ ] Multi-language support
- [ ] Export API (CSV, PDF)

---

## üë• Team

**Null Coders**  
Track India Hackathon Project ‚Ä¢ 2025

---

## üìù License

MIT License - See LICENSE file for details

---

## ü§ù Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

---

## üìû Support

For issues and questions:

- Create an issue on GitHub
- Contact: team@nullcoders.dev

---

**Built with ‚ù§Ô∏è for India's Development Tracking**
